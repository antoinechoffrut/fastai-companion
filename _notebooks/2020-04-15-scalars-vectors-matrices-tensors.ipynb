{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalars, vectors, matrices, and tensors\n",
    ">Correspodence between mathematics and PyTorch.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [mathematics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "tags: scalars vectors matrices tensors mathematics linear algebra pytorch  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tl;dr\n",
    "We establish the following correspondence between entities commonly encountered in linear algebra and their counterparts in `PyTorch`.\n",
    "\n",
    "|mathematical name|mathematical notation|`tensor` shape|`tensor` dimension|\n",
    "|---|---|---|---|\n",
    "|scalar|$x$|`()`|`0`|\n",
    "|vector|$(x_1, \\dots, x_n)$|`(n,)`|`1`|\n",
    "|linear transform| $w_{i,j}$ <br> $i=1, \\dots, m$<br>$j=1, \\dots, n$|N/A|N/A|\n",
    "|matrix|$\\begin{bmatrix}w_{1,1}&\\dots&w_{1,n}\\\\\\vdots&\\ddots&\\vdots\\\\w_{m,1}&\\dots&w_{n,m}\\end{bmatrix}$|`(m,n)`| `2`|\n",
    "|column vector|$\\begin{bmatrix}x_1\\\\\\vdots\\\\x_n\\end{bmatrix}$|`(n,1)`|`2`|\n",
    "|row vector|$\\begin{bmatrix}x_1&\\dots&x_n\\end{bmatrix}$|`(1,n)`|`2`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note:\n",
    "When we write `tensor`, we mean a `PyTorch` `tensor`.  Otherwise, \"tensor\" refers to the mathematical notion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Important:\n",
    "The dimension of a _vector_ is the number of its entries.  The dimension of a _tensor_ is the number of indices needed to label its entries, in other words the length of its shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: As a consequence, it is enough to refer to a `(m,n)`-`tensor` rather than to a `2`-dimensional `tensor` with shape `(m,n)`, but at times we will want to emphasize the dimension and make the information explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalars\n",
    "A scalar is a real number.  It corresponds to a `0`-dimensional `tensor` with empty shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a 0-dimensional tensor in PyTorch:\n",
      "---------------------------------------------\n",
      "tensor(3.1400)\n",
      "\n",
      "Dimension:   0\n",
      "Shape:       ()\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "x = tensor(3.14)\n",
    "print(\"Example of a 0-dimensional tensor in PyTorch:\")\n",
    "print(\"-\"*45)\n",
    "print(x)\n",
    "print(f\"\\nDimension:   {x.ndim}\")\n",
    "print(f\"Shape:       {tuple(x.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors\n",
    "An $n$-dimensional vector is a **list** of $n$ scalars:\n",
    "\\begin{equation}(x_1, \\dots, x_n)\\,.\\end{equation}\n",
    "It corresponds to a `0`-dimensional `tensor` of shape `(n,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a 1-dimensional tensor in PyTorch:\n",
      "---------------------------------------------\n",
      "tensor([-1.,  5.,  7.])\n",
      "\n",
      "Dimension:   1\n",
      "Shape:       (3,)\n"
     ]
    }
   ],
   "source": [
    "# collapse-show\n",
    "from torch import tensor\n",
    "x = tensor([-1., 5., 7.])\n",
    "print(\"Example of a 1-dimensional tensor in PyTorch:\")\n",
    "print(\"-\"*45)\n",
    "print(x)\n",
    "print(f\"\\nDimension:   {x.ndim}\")\n",
    "print(f\"Shape:       {tuple(x.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear transformations\n",
    "A linear transformation which maps $n$-dimensional vectors to $m$-dimensional vectors can be identified with a doubly-indexed list of scalars $w_{i,j}$ where $i$ runs from $1$ to $m$ and $j$ from $1$ to $n$, in that they act on input vectors according to the familiar formula:\n",
    "$$y_i = \\sum_{j=1}^nw_{i,j}x_j\\quad \\textrm{for}\\quad i=1, \\dots, m\\,.$$\n",
    "\n",
    ">Tip:\n",
    "The indices in $w_{i,j}x_j$ appear in the order $(i, j, j)$.  The dummy index $j$ is repeated next to itself and \"disappears\" upon summation, while the index $i$ remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column vectors\n",
    "For computational purposes, instead of a vector $(x_1, \\dots, x_n)$, it is convenient to work with its **column vector** counterpart, which is the array\n",
    "$$\\begin{bmatrix}x_1\\\\\\vdots\\\\x_n\\end{bmatrix}\\,.\n",
    "$$\n",
    ">Important:\n",
    "It is important to distinguish a vector and its corresponding column vector:\n",
    "$$(x_1, \\dots, x_n) \\quad \\ne\\quad \\begin{bmatrix}x_1\\\\\\vdots\\\\x_n\\end{bmatrix}\\,.$$  \n",
    "\n",
    "Indeed, while the vector corresponds to a `1`-dimensional `tensor`, its column vector counterpart corresponds to a `2`-dimensional `tensor` with shape `(n,1)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a 1-dimensional tensor in PyTorch:\n",
      "---------------------------------------------\n",
      "tensor([[-1.],\n",
      "        [ 5.],\n",
      "        [ 7.]])\n",
      "\n",
      "Dimension:   2\n",
      "Shape:       (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# collapse-show\n",
    "from torch import tensor\n",
    "x = tensor([-1., 5., 7.]).reshape(-1, 1)\n",
    "print(\"Example of a 1-dimensional tensor in PyTorch:\")\n",
    "print(\"-\"*45)\n",
    "print(x)\n",
    "print(f\"\\nDimension:   {x.ndim}\")\n",
    "print(f\"Shape:       {tuple(x.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices\n",
    "An **$m$-by-$n$ matrix** is a doubly-indexed list $w_{i,j}$ where $i$ ranges from $1$ to $m$ and $j$ from $1$ to $n$.  It is usually written as an array with $m$ rows and $n$ columns:\n",
    "$$\\begin{bmatrix}\n",
    "w_{1,1}&\\dots&w_{1,j}&\\dots&w_{1,n}\\\\\n",
    "\\vdots&&\\vdots&&\\vdots\\\\\n",
    "w_{i,1}&\\dots&w_{i,j}&\\dots&w_{i,n}\\\\\n",
    "\\vdots&&\\vdots&&\\vdots\\\\\n",
    "w_{m,1}&\\dots&w_{m,j}&\\dots&w_{m,n}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Important:\n",
    "The first index in $w_{i,j}$ labels rows and the second index labels columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An $m$-by-$n$ matrix corresponds to a `2`-dimensional`tensor` with shape `(m,n)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a 2-dimensional tensor in PyTorch:\n",
      "---------------------------------------------\n",
      "tensor([[-0.3536,  1.9439, -0.0042, -0.8287],\n",
      "        [-0.4937,  0.4641, -1.0579,  0.2006],\n",
      "        [-0.4996, -1.2149, -0.9282,  0.1443]])\n",
      "\n",
      "Dimension:   2\n",
      "Shape:       (3, 4)\n"
     ]
    }
   ],
   "source": [
    "# collapse-show\n",
    "import torch\n",
    "n = 3\n",
    "m = 4\n",
    "x = torch.randn(n, m)\n",
    "print(\"Example of a 2-dimensional tensor in PyTorch:\")\n",
    "print(\"-\"*45)\n",
    "print(x)\n",
    "print(f\"\\nDimension:   {x.ndim}\")\n",
    "print(f\"Shape:       {tuple(x.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation and compact representation of linear transformations\n",
    "The _collection_ of $m$ formulas $y_i = \\sum_{j=1}^nw_{i,j}x_j$, where $i$ runs from $1$ to $m$, is compactly represented as\n",
    "$$\n",
    "\\begin{bmatrix}y_1\\\\\\vdots\\\\y_m\\end{bmatrix}\n",
    "\\,=\\,\\begin{bmatrix}w_{1,1}&\\dots&w_{1,n}\\\\\\vdots&\\ddots&\\vdots\\\\w_{m,1}&\\dots&w_{m,n}\\end{bmatrix}\n",
    "\\begin{bmatrix}x_1\\\\\\vdots\\\\x_n\\end{bmatrix}\n",
    "$$\n",
    "where the matrix is written to the left of the input column vector.\n",
    "\n",
    ">Note:\n",
    "The number of columns in the matrix matches the number of rows in the column vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row vectors\n",
    "Identifying a vector with its column vector is the more common convention.  Alternatively, the vector $(x_1, \\dots, x_n)$ can be identified with its **row vector** counterpart, which is the array\n",
    "$$\\begin{bmatrix}x_1&\\dots&x_n\\end{bmatrix}\\,.$$\n",
    "\n",
    ">Important:\n",
    "Again, a vector, its column and row vector counterparts are all different objects:\n",
    "$$(x_1, \\dots, x_n) \\quad \\ne \\quad \\begin{bmatrix}x_1\\\\\\vdots\\\\x_n\\end{bmatrix}\n",
    "\\quad\\ne\\quad\n",
    "\\begin{bmatrix}x_1&\\dots&x_n\\end{bmatrix}\n",
    "\\quad\\ne\\quad\n",
    "(x_1, \\dots, x_n)\\,.$$  \n",
    "\n",
    "Indeed, a row vector of length $n$ corresponds to a `2`-dimensional `tensor` with shape `(1,n)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of a 1-dimensional tensor in PyTorch:\n",
      "---------------------------------------------\n",
      "tensor([[-1.,  5.,  7.]])\n",
      "\n",
      "Dimension:   2\n",
      "Shape:       (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# collapse-show\n",
    "from torch import tensor\n",
    "x = tensor([-1., 5., 7.]).reshape(1, -1)\n",
    "print(\"Example of a 1-dimensional tensor in PyTorch:\")\n",
    "print(\"-\"*45)\n",
    "print(x)\n",
    "print(f\"\\nDimension:   {x.ndim}\")\n",
    "print(f\"Shape:       {tuple(x.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note:\n",
    "Vectors and row vectors are all represented horizontally.  However, vectors are written with parentheses while row vectors are written with square brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing with row vectors\n",
    "In terms of row vectors, the output of a linear transformation is more conveniently rewritten with the similar but different formulas\n",
    "$$y_j = \\sum_{i=1}^nx_i\\tilde w_{i,j}\\qquad \\textrm{for}\\quad j=1, \\dots, m$$\n",
    "where now the matrix with coefficients $\\tilde w_{i,j}$ where $i$ runs from $1$ to $n$ and $j$ from $1$ to $m$, has $n$ rows and $m$ columns:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\tilde w_{1,1}&\\dots&\\tilde w_{1,j}&\\dots&\\tilde w_{1,m}\\\\\n",
    "\\vdots&&\\vdots&&\\vdots\\\\\n",
    "\\tilde w_{i,1}&\\dots&\\tilde w_{i,j}&\\dots&\\tilde w_{i,m}\\\\\n",
    "\\vdots&&\\vdots&&\\vdots\\\\\n",
    "\\tilde w_{n,1}&\\dots&\\tilde w_{n,i}&\\dots&\\tilde w_{n,m}\n",
    "\\end{bmatrix}\\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Tip:\n",
    "The indices in $x_i\\tilde w_{i,j}$ appear in the order $(i, i, j)$ (note the difference from earlier).  The dummy index, which is now $i$, is repeated next to itself.  The remaining index, which is now $j$, is the same as that in the quantity $y_j$ on the left of the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of $m$ formulas $y_j = \\sum_{i=1}^nx_i\\tilde w_{i,j}$, for $j$ from $1$ to $m$, is compactly represented as\n",
    "$$\n",
    "\\begin{bmatrix}y_1&\\dots&y_m\\end{bmatrix}\n",
    "\\quad=\\quad\n",
    "\\begin{bmatrix}x_1&\\dots&x_n\\end{bmatrix}\n",
    "\\begin{bmatrix}\\tilde w_{1,1}&\\dots&\\tilde w_{1,m}\\\\\\vdots&\\ddots&\\vdots\\\\\\tilde w_{n,1}&\\dots&\\tilde w_{n,m}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where the matrix is written to the right of the input row vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note:\n",
    "The number of columns in the input row vector matches the number of rows in the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Important:\n",
    "The coefficients $\\tilde w_{i,j}$ share the same values as the coefficients $w_{i,j}$ in the representation with column vectors, but they are coefficients of distinct matrices: the first is $n$-by-$m$ while the second is $m$-by-$n$.  In fact, these matrices are transposes of each other:\n",
    "$$\n",
    "\\begin{bmatrix}\\tilde w_{1,1}&\\dots&\\tilde w_{1,m}\\\\\\vdots&\\ddots&\\vdots\\\\\\tilde w_{n,1}&\\dots&\\tilde w_{n,m}\n",
    "\\end{bmatrix}\n",
    "\\quad=\\quad\n",
    "\\begin{bmatrix}w_{1,1}&\\dots&w_{1,n}\\\\\\vdots&\\ddots&\\vdots\\\\w_{m,1}&\\dots&w_{m,n}\\end{bmatrix}^\\top\n",
    "\\quad=\\quad\n",
    "\\begin{bmatrix}w_{1,1}&\\dots&w_{m,1}\\\\\\vdots&\\ddots&\\vdots\\\\w_{1,n}&\\dots&w_{m,n}\\end{bmatrix}\n",
    "\\,.$$\n",
    "Equivalently,\n",
    "$$\\tilde w_{i,j} = w_{j,i}\\qquad \\textrm{for}\\quad i=1, \\dots, n\\,,\\quad j=1, \\dots, m\\,.$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
